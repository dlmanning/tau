// This file is auto-generated by `cargo xtask generate-models`.
// Do not edit manually.

#[derive(Debug, Clone, Copy)]
pub(crate) struct ModelEntry {
    pub id: &'static str,
    pub name: &'static str,
    pub provider: &'static str,
    pub api: &'static str,
    pub base_url: &'static str,
    pub reasoning: bool,
    pub input_text: bool,
    pub input_image: bool,
    pub cost_input: f64,
    pub cost_output: f64,
    pub cost_cache_read: f64,
    pub cost_cache_write: f64,
    pub cost_thinking: f64,
    pub context_window: u32,
    pub max_tokens: u32,
}

pub(crate) const MODEL_ENTRIES: &[ModelEntry] = &[
    ModelEntry {
        id: "claude-3-5-haiku-20241022",
        name: "Claude Haiku 3.5",
        provider: "Anthropic",
        api: "AnthropicMessages",
        base_url: "https://api.anthropic.com",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 0.8,
        cost_output: 4.0,
        cost_cache_read: 0.08,
        cost_cache_write: 1.0,
        cost_thinking: 0.0,
        context_window: 200000,
        max_tokens: 8192,
    },
    ModelEntry {
        id: "claude-3-5-haiku-latest",
        name: "Claude Haiku 3.5 (latest)",
        provider: "Anthropic",
        api: "AnthropicMessages",
        base_url: "https://api.anthropic.com",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 0.8,
        cost_output: 4.0,
        cost_cache_read: 0.08,
        cost_cache_write: 1.0,
        cost_thinking: 0.0,
        context_window: 200000,
        max_tokens: 8192,
    },
    ModelEntry {
        id: "claude-3-7-sonnet-20250219",
        name: "Claude Sonnet 3.7",
        provider: "Anthropic",
        api: "AnthropicMessages",
        base_url: "https://api.anthropic.com",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 3.0,
        cost_output: 15.0,
        cost_cache_read: 0.3,
        cost_cache_write: 3.75,
        cost_thinking: 15.0,
        context_window: 200000,
        max_tokens: 64000,
    },
    ModelEntry {
        id: "claude-3-7-sonnet-latest",
        name: "Claude Sonnet 3.7 (latest)",
        provider: "Anthropic",
        api: "AnthropicMessages",
        base_url: "https://api.anthropic.com",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 3.0,
        cost_output: 15.0,
        cost_cache_read: 0.3,
        cost_cache_write: 3.75,
        cost_thinking: 15.0,
        context_window: 200000,
        max_tokens: 64000,
    },
    ModelEntry {
        id: "claude-3-haiku-20240307",
        name: "Claude Haiku 3",
        provider: "Anthropic",
        api: "AnthropicMessages",
        base_url: "https://api.anthropic.com",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 0.25,
        cost_output: 1.25,
        cost_cache_read: 0.03,
        cost_cache_write: 0.3,
        cost_thinking: 0.0,
        context_window: 200000,
        max_tokens: 4096,
    },
    ModelEntry {
        id: "claude-haiku-4-5",
        name: "Claude Haiku 4.5 (latest)",
        provider: "Anthropic",
        api: "AnthropicMessages",
        base_url: "https://api.anthropic.com",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 1.0,
        cost_output: 5.0,
        cost_cache_read: 0.1,
        cost_cache_write: 1.25,
        cost_thinking: 5.0,
        context_window: 200000,
        max_tokens: 64000,
    },
    ModelEntry {
        id: "claude-haiku-4-5-20251001",
        name: "Claude Haiku 4.5",
        provider: "Anthropic",
        api: "AnthropicMessages",
        base_url: "https://api.anthropic.com",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 1.0,
        cost_output: 5.0,
        cost_cache_read: 0.1,
        cost_cache_write: 1.25,
        cost_thinking: 5.0,
        context_window: 200000,
        max_tokens: 64000,
    },
    ModelEntry {
        id: "claude-opus-4-0",
        name: "Claude Opus 4 (latest)",
        provider: "Anthropic",
        api: "AnthropicMessages",
        base_url: "https://api.anthropic.com",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 15.0,
        cost_output: 75.0,
        cost_cache_read: 1.5,
        cost_cache_write: 18.75,
        cost_thinking: 75.0,
        context_window: 200000,
        max_tokens: 32000,
    },
    ModelEntry {
        id: "claude-opus-4-1",
        name: "Claude Opus 4.1 (latest)",
        provider: "Anthropic",
        api: "AnthropicMessages",
        base_url: "https://api.anthropic.com",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 15.0,
        cost_output: 75.0,
        cost_cache_read: 1.5,
        cost_cache_write: 18.75,
        cost_thinking: 75.0,
        context_window: 200000,
        max_tokens: 32000,
    },
    ModelEntry {
        id: "claude-opus-4-1-20250805",
        name: "Claude Opus 4.1",
        provider: "Anthropic",
        api: "AnthropicMessages",
        base_url: "https://api.anthropic.com",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 15.0,
        cost_output: 75.0,
        cost_cache_read: 1.5,
        cost_cache_write: 18.75,
        cost_thinking: 75.0,
        context_window: 200000,
        max_tokens: 32000,
    },
    ModelEntry {
        id: "claude-opus-4-20250514",
        name: "Claude Opus 4",
        provider: "Anthropic",
        api: "AnthropicMessages",
        base_url: "https://api.anthropic.com",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 15.0,
        cost_output: 75.0,
        cost_cache_read: 1.5,
        cost_cache_write: 18.75,
        cost_thinking: 75.0,
        context_window: 200000,
        max_tokens: 32000,
    },
    ModelEntry {
        id: "claude-opus-4-5",
        name: "Claude Opus 4.5 (latest)",
        provider: "Anthropic",
        api: "AnthropicMessages",
        base_url: "https://api.anthropic.com",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 5.0,
        cost_output: 25.0,
        cost_cache_read: 0.5,
        cost_cache_write: 6.25,
        cost_thinking: 25.0,
        context_window: 200000,
        max_tokens: 64000,
    },
    ModelEntry {
        id: "claude-opus-4-5-20251101",
        name: "Claude Opus 4.5",
        provider: "Anthropic",
        api: "AnthropicMessages",
        base_url: "https://api.anthropic.com",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 5.0,
        cost_output: 25.0,
        cost_cache_read: 0.5,
        cost_cache_write: 6.25,
        cost_thinking: 25.0,
        context_window: 200000,
        max_tokens: 64000,
    },
    ModelEntry {
        id: "claude-opus-4-6",
        name: "Claude Opus 4.6",
        provider: "Anthropic",
        api: "AnthropicMessages",
        base_url: "https://api.anthropic.com",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 5.0,
        cost_output: 25.0,
        cost_cache_read: 0.5,
        cost_cache_write: 6.25,
        cost_thinking: 25.0,
        context_window: 200000,
        max_tokens: 128000,
    },
    ModelEntry {
        id: "claude-sonnet-4-0",
        name: "Claude Sonnet 4 (latest)",
        provider: "Anthropic",
        api: "AnthropicMessages",
        base_url: "https://api.anthropic.com",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 3.0,
        cost_output: 15.0,
        cost_cache_read: 0.3,
        cost_cache_write: 3.75,
        cost_thinking: 15.0,
        context_window: 200000,
        max_tokens: 64000,
    },
    ModelEntry {
        id: "claude-sonnet-4-20250514",
        name: "Claude Sonnet 4",
        provider: "Anthropic",
        api: "AnthropicMessages",
        base_url: "https://api.anthropic.com",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 3.0,
        cost_output: 15.0,
        cost_cache_read: 0.3,
        cost_cache_write: 3.75,
        cost_thinking: 15.0,
        context_window: 200000,
        max_tokens: 64000,
    },
    ModelEntry {
        id: "claude-sonnet-4-5",
        name: "Claude Sonnet 4.5 (latest)",
        provider: "Anthropic",
        api: "AnthropicMessages",
        base_url: "https://api.anthropic.com",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 3.0,
        cost_output: 15.0,
        cost_cache_read: 0.3,
        cost_cache_write: 3.75,
        cost_thinking: 15.0,
        context_window: 200000,
        max_tokens: 64000,
    },
    ModelEntry {
        id: "claude-sonnet-4-5-20250929",
        name: "Claude Sonnet 4.5",
        provider: "Anthropic",
        api: "AnthropicMessages",
        base_url: "https://api.anthropic.com",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 3.0,
        cost_output: 15.0,
        cost_cache_read: 0.3,
        cost_cache_write: 3.75,
        cost_thinking: 15.0,
        context_window: 200000,
        max_tokens: 64000,
    },
    ModelEntry {
        id: "gpt-oss-120b",
        name: "GPT OSS 120B",
        provider: "Cerebras",
        api: "OpenAICompletions",
        base_url: "https://api.cerebras.ai/v1",
        reasoning: true,
        input_text: true,
        input_image: false,
        cost_input: 0.25,
        cost_output: 0.69,
        cost_cache_read: 0.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.69,
        context_window: 131072,
        max_tokens: 32768,
    },
    ModelEntry {
        id: "llama3.1-8b",
        name: "Llama 3.1 8B",
        provider: "Cerebras",
        api: "OpenAICompletions",
        base_url: "https://api.cerebras.ai/v1",
        reasoning: false,
        input_text: true,
        input_image: false,
        cost_input: 0.1,
        cost_output: 0.1,
        cost_cache_read: 0.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 32000,
        max_tokens: 8000,
    },
    ModelEntry {
        id: "qwen-3-235b-a22b-instruct-2507",
        name: "Qwen 3 235B Instruct",
        provider: "Cerebras",
        api: "OpenAICompletions",
        base_url: "https://api.cerebras.ai/v1",
        reasoning: false,
        input_text: true,
        input_image: false,
        cost_input: 0.6,
        cost_output: 1.2,
        cost_cache_read: 0.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 131000,
        max_tokens: 32000,
    },
    ModelEntry {
        id: "zai-glm-4.7",
        name: "Z.AI GLM-4.7",
        provider: "Cerebras",
        api: "OpenAICompletions",
        base_url: "https://api.cerebras.ai/v1",
        reasoning: false,
        input_text: true,
        input_image: false,
        cost_input: 0.0,
        cost_output: 0.0,
        cost_cache_read: 0.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 131072,
        max_tokens: 40000,
    },
    ModelEntry {
        id: "gemini-1.5-flash",
        name: "Gemini 1.5 Flash",
        provider: "Google",
        api: "GoogleGenerativeAI",
        base_url: "https://generativelanguage.googleapis.com/v1beta",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 0.075,
        cost_output: 0.3,
        cost_cache_read: 0.01875,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 1000000,
        max_tokens: 8192,
    },
    ModelEntry {
        id: "gemini-1.5-flash-8b",
        name: "Gemini 1.5 Flash-8B",
        provider: "Google",
        api: "GoogleGenerativeAI",
        base_url: "https://generativelanguage.googleapis.com/v1beta",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 0.0375,
        cost_output: 0.15,
        cost_cache_read: 0.01,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 1000000,
        max_tokens: 8192,
    },
    ModelEntry {
        id: "gemini-1.5-pro",
        name: "Gemini 1.5 Pro",
        provider: "Google",
        api: "GoogleGenerativeAI",
        base_url: "https://generativelanguage.googleapis.com/v1beta",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 1.25,
        cost_output: 5.0,
        cost_cache_read: 0.3125,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 1000000,
        max_tokens: 8192,
    },
    ModelEntry {
        id: "gemini-2.0-flash",
        name: "Gemini 2.0 Flash",
        provider: "Google",
        api: "GoogleGenerativeAI",
        base_url: "https://generativelanguage.googleapis.com/v1beta",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 0.1,
        cost_output: 0.4,
        cost_cache_read: 0.025,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 1048576,
        max_tokens: 8192,
    },
    ModelEntry {
        id: "gemini-2.0-flash-lite",
        name: "Gemini 2.0 Flash Lite",
        provider: "Google",
        api: "GoogleGenerativeAI",
        base_url: "https://generativelanguage.googleapis.com/v1beta",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 0.075,
        cost_output: 0.3,
        cost_cache_read: 0.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 1048576,
        max_tokens: 8192,
    },
    ModelEntry {
        id: "gemini-2.5-flash",
        name: "Gemini 2.5 Flash",
        provider: "Google",
        api: "GoogleGenerativeAI",
        base_url: "https://generativelanguage.googleapis.com/v1beta",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 0.3,
        cost_output: 2.5,
        cost_cache_read: 0.075,
        cost_cache_write: 0.0,
        cost_thinking: 2.5,
        context_window: 1048576,
        max_tokens: 65536,
    },
    ModelEntry {
        id: "gemini-2.5-flash-lite",
        name: "Gemini 2.5 Flash Lite",
        provider: "Google",
        api: "GoogleGenerativeAI",
        base_url: "https://generativelanguage.googleapis.com/v1beta",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 0.1,
        cost_output: 0.4,
        cost_cache_read: 0.025,
        cost_cache_write: 0.0,
        cost_thinking: 0.4,
        context_window: 1048576,
        max_tokens: 65536,
    },
    ModelEntry {
        id: "gemini-2.5-flash-lite-preview-06-17",
        name: "Gemini 2.5 Flash Lite Preview 06-17",
        provider: "Google",
        api: "GoogleGenerativeAI",
        base_url: "https://generativelanguage.googleapis.com/v1beta",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 0.1,
        cost_output: 0.4,
        cost_cache_read: 0.025,
        cost_cache_write: 0.0,
        cost_thinking: 0.4,
        context_window: 1048576,
        max_tokens: 65536,
    },
    ModelEntry {
        id: "gemini-2.5-flash-lite-preview-09-2025",
        name: "Gemini 2.5 Flash Lite Preview 09-25",
        provider: "Google",
        api: "GoogleGenerativeAI",
        base_url: "https://generativelanguage.googleapis.com/v1beta",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 0.1,
        cost_output: 0.4,
        cost_cache_read: 0.025,
        cost_cache_write: 0.0,
        cost_thinking: 0.4,
        context_window: 1048576,
        max_tokens: 65536,
    },
    ModelEntry {
        id: "gemini-2.5-flash-preview-04-17",
        name: "Gemini 2.5 Flash Preview 04-17",
        provider: "Google",
        api: "GoogleGenerativeAI",
        base_url: "https://generativelanguage.googleapis.com/v1beta",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 0.15,
        cost_output: 0.6,
        cost_cache_read: 0.0375,
        cost_cache_write: 0.0,
        cost_thinking: 0.6,
        context_window: 1048576,
        max_tokens: 65536,
    },
    ModelEntry {
        id: "gemini-2.5-flash-preview-05-20",
        name: "Gemini 2.5 Flash Preview 05-20",
        provider: "Google",
        api: "GoogleGenerativeAI",
        base_url: "https://generativelanguage.googleapis.com/v1beta",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 0.15,
        cost_output: 0.6,
        cost_cache_read: 0.0375,
        cost_cache_write: 0.0,
        cost_thinking: 0.6,
        context_window: 1048576,
        max_tokens: 65536,
    },
    ModelEntry {
        id: "gemini-2.5-flash-preview-09-2025",
        name: "Gemini 2.5 Flash Preview 09-25",
        provider: "Google",
        api: "GoogleGenerativeAI",
        base_url: "https://generativelanguage.googleapis.com/v1beta",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 0.3,
        cost_output: 2.5,
        cost_cache_read: 0.075,
        cost_cache_write: 0.0,
        cost_thinking: 2.5,
        context_window: 1048576,
        max_tokens: 65536,
    },
    ModelEntry {
        id: "gemini-2.5-pro",
        name: "Gemini 2.5 Pro",
        provider: "Google",
        api: "GoogleGenerativeAI",
        base_url: "https://generativelanguage.googleapis.com/v1beta",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 1.25,
        cost_output: 10.0,
        cost_cache_read: 0.31,
        cost_cache_write: 0.0,
        cost_thinking: 10.0,
        context_window: 1048576,
        max_tokens: 65536,
    },
    ModelEntry {
        id: "gemini-2.5-pro-preview-05-06",
        name: "Gemini 2.5 Pro Preview 05-06",
        provider: "Google",
        api: "GoogleGenerativeAI",
        base_url: "https://generativelanguage.googleapis.com/v1beta",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 1.25,
        cost_output: 10.0,
        cost_cache_read: 0.31,
        cost_cache_write: 0.0,
        cost_thinking: 10.0,
        context_window: 1048576,
        max_tokens: 65536,
    },
    ModelEntry {
        id: "gemini-2.5-pro-preview-06-05",
        name: "Gemini 2.5 Pro Preview 06-05",
        provider: "Google",
        api: "GoogleGenerativeAI",
        base_url: "https://generativelanguage.googleapis.com/v1beta",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 1.25,
        cost_output: 10.0,
        cost_cache_read: 0.31,
        cost_cache_write: 0.0,
        cost_thinking: 10.0,
        context_window: 1048576,
        max_tokens: 65536,
    },
    ModelEntry {
        id: "gemini-3-flash-preview",
        name: "Gemini 3 Flash Preview",
        provider: "Google",
        api: "GoogleGenerativeAI",
        base_url: "https://generativelanguage.googleapis.com/v1beta",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 0.5,
        cost_output: 3.0,
        cost_cache_read: 0.05,
        cost_cache_write: 0.0,
        cost_thinking: 3.0,
        context_window: 1048576,
        max_tokens: 65536,
    },
    ModelEntry {
        id: "gemini-3-pro-preview",
        name: "Gemini 3 Pro Preview",
        provider: "Google",
        api: "GoogleGenerativeAI",
        base_url: "https://generativelanguage.googleapis.com/v1beta",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 2.0,
        cost_output: 12.0,
        cost_cache_read: 0.2,
        cost_cache_write: 0.0,
        cost_thinking: 12.0,
        context_window: 1000000,
        max_tokens: 64000,
    },
    ModelEntry {
        id: "gemini-flash-latest",
        name: "Gemini Flash Latest",
        provider: "Google",
        api: "GoogleGenerativeAI",
        base_url: "https://generativelanguage.googleapis.com/v1beta",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 0.3,
        cost_output: 2.5,
        cost_cache_read: 0.075,
        cost_cache_write: 0.0,
        cost_thinking: 2.5,
        context_window: 1048576,
        max_tokens: 65536,
    },
    ModelEntry {
        id: "gemini-flash-lite-latest",
        name: "Gemini Flash-Lite Latest",
        provider: "Google",
        api: "GoogleGenerativeAI",
        base_url: "https://generativelanguage.googleapis.com/v1beta",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 0.1,
        cost_output: 0.4,
        cost_cache_read: 0.025,
        cost_cache_write: 0.0,
        cost_thinking: 0.4,
        context_window: 1048576,
        max_tokens: 65536,
    },
    ModelEntry {
        id: "gemini-live-2.5-flash",
        name: "Gemini Live 2.5 Flash",
        provider: "Google",
        api: "GoogleGenerativeAI",
        base_url: "https://generativelanguage.googleapis.com/v1beta",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 0.5,
        cost_output: 2.0,
        cost_cache_read: 0.0,
        cost_cache_write: 0.0,
        cost_thinking: 2.0,
        context_window: 128000,
        max_tokens: 8000,
    },
    ModelEntry {
        id: "gemini-live-2.5-flash-preview-native-audio",
        name: "Gemini Live 2.5 Flash Preview Native Audio",
        provider: "Google",
        api: "GoogleGenerativeAI",
        base_url: "https://generativelanguage.googleapis.com/v1beta",
        reasoning: true,
        input_text: true,
        input_image: false,
        cost_input: 0.5,
        cost_output: 2.0,
        cost_cache_read: 0.0,
        cost_cache_write: 0.0,
        cost_thinking: 2.0,
        context_window: 131072,
        max_tokens: 65536,
    },
    ModelEntry {
        id: "llama-3.1-8b-instant",
        name: "Llama 3.1 8B Instant",
        provider: "Groq",
        api: "OpenAICompletions",
        base_url: "https://api.groq.com/openai/v1",
        reasoning: false,
        input_text: true,
        input_image: false,
        cost_input: 0.05,
        cost_output: 0.08,
        cost_cache_read: 0.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 131072,
        max_tokens: 131072,
    },
    ModelEntry {
        id: "llama-3.3-70b-versatile",
        name: "Llama 3.3 70B Versatile",
        provider: "Groq",
        api: "OpenAICompletions",
        base_url: "https://api.groq.com/openai/v1",
        reasoning: false,
        input_text: true,
        input_image: false,
        cost_input: 0.59,
        cost_output: 0.79,
        cost_cache_read: 0.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 131072,
        max_tokens: 32768,
    },
    ModelEntry {
        id: "meta-llama/llama-4-maverick-17b-128e-instruct",
        name: "Llama 4 Maverick 17B",
        provider: "Groq",
        api: "OpenAICompletions",
        base_url: "https://api.groq.com/openai/v1",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 0.2,
        cost_output: 0.6,
        cost_cache_read: 0.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 131072,
        max_tokens: 8192,
    },
    ModelEntry {
        id: "meta-llama/llama-4-scout-17b-16e-instruct",
        name: "Llama 4 Scout 17B",
        provider: "Groq",
        api: "OpenAICompletions",
        base_url: "https://api.groq.com/openai/v1",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 0.11,
        cost_output: 0.34,
        cost_cache_read: 0.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 131072,
        max_tokens: 8192,
    },
    ModelEntry {
        id: "moonshotai/kimi-k2-instruct-0905",
        name: "Kimi K2 Instruct 0905",
        provider: "Groq",
        api: "OpenAICompletions",
        base_url: "https://api.groq.com/openai/v1",
        reasoning: false,
        input_text: true,
        input_image: false,
        cost_input: 1.0,
        cost_output: 3.0,
        cost_cache_read: 0.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 262144,
        max_tokens: 16384,
    },
    ModelEntry {
        id: "openai/gpt-oss-120b",
        name: "GPT OSS 120B",
        provider: "Groq",
        api: "OpenAICompletions",
        base_url: "https://api.groq.com/openai/v1",
        reasoning: true,
        input_text: true,
        input_image: false,
        cost_input: 0.15,
        cost_output: 0.6,
        cost_cache_read: 0.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.6,
        context_window: 131072,
        max_tokens: 65536,
    },
    ModelEntry {
        id: "openai/gpt-oss-20b",
        name: "GPT OSS 20B",
        provider: "Groq",
        api: "OpenAICompletions",
        base_url: "https://api.groq.com/openai/v1",
        reasoning: true,
        input_text: true,
        input_image: false,
        cost_input: 0.075,
        cost_output: 0.3,
        cost_cache_read: 0.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.3,
        context_window: 131072,
        max_tokens: 65536,
    },
    ModelEntry {
        id: "qwen/qwen3-32b",
        name: "Qwen3 32B",
        provider: "Groq",
        api: "OpenAICompletions",
        base_url: "https://api.groq.com/openai/v1",
        reasoning: true,
        input_text: true,
        input_image: false,
        cost_input: 0.29,
        cost_output: 0.59,
        cost_cache_read: 0.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.59,
        context_window: 131072,
        max_tokens: 16384,
    },
    ModelEntry {
        id: "codex-mini-latest",
        name: "Codex Mini",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: false,
        cost_input: 1.5,
        cost_output: 6.0,
        cost_cache_read: 0.375,
        cost_cache_write: 0.0,
        cost_thinking: 6.0,
        context_window: 200000,
        max_tokens: 100000,
    },
    ModelEntry {
        id: "gpt-4",
        name: "GPT-4",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: false,
        input_text: true,
        input_image: false,
        cost_input: 30.0,
        cost_output: 60.0,
        cost_cache_read: 0.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 8192,
        max_tokens: 8192,
    },
    ModelEntry {
        id: "gpt-4-turbo",
        name: "GPT-4 Turbo",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 10.0,
        cost_output: 30.0,
        cost_cache_read: 0.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 128000,
        max_tokens: 4096,
    },
    ModelEntry {
        id: "gpt-4.1",
        name: "GPT-4.1",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 2.0,
        cost_output: 8.0,
        cost_cache_read: 0.5,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 1048576,
        max_tokens: 32768,
    },
    ModelEntry {
        id: "gpt-4.1-mini",
        name: "GPT-4.1 mini",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 0.4,
        cost_output: 1.6,
        cost_cache_read: 0.1,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 1048576,
        max_tokens: 32768,
    },
    ModelEntry {
        id: "gpt-4.1-nano",
        name: "GPT-4.1 nano",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 0.1,
        cost_output: 0.4,
        cost_cache_read: 0.03,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 1048576,
        max_tokens: 32768,
    },
    ModelEntry {
        id: "gpt-4o",
        name: "GPT-4o",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 2.5,
        cost_output: 10.0,
        cost_cache_read: 1.25,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 128000,
        max_tokens: 16384,
    },
    ModelEntry {
        id: "gpt-4o-2024-05-13",
        name: "GPT-4o (2024-05-13)",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 5.0,
        cost_output: 15.0,
        cost_cache_read: 0.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 128000,
        max_tokens: 4096,
    },
    ModelEntry {
        id: "gpt-4o-2024-08-06",
        name: "GPT-4o (2024-08-06)",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 2.5,
        cost_output: 10.0,
        cost_cache_read: 1.25,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 128000,
        max_tokens: 16384,
    },
    ModelEntry {
        id: "gpt-4o-2024-11-20",
        name: "GPT-4o (2024-11-20)",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 2.5,
        cost_output: 10.0,
        cost_cache_read: 1.25,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 128000,
        max_tokens: 16384,
    },
    ModelEntry {
        id: "gpt-4o-mini",
        name: "GPT-4o mini",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 0.15,
        cost_output: 0.6,
        cost_cache_read: 0.08,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 128000,
        max_tokens: 16384,
    },
    ModelEntry {
        id: "gpt-5",
        name: "GPT-5",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 1.25,
        cost_output: 10.0,
        cost_cache_read: 0.125,
        cost_cache_write: 0.0,
        cost_thinking: 10.0,
        context_window: 400000,
        max_tokens: 128000,
    },
    ModelEntry {
        id: "gpt-5-codex",
        name: "GPT-5-Codex",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 1.25,
        cost_output: 10.0,
        cost_cache_read: 0.125,
        cost_cache_write: 0.0,
        cost_thinking: 10.0,
        context_window: 400000,
        max_tokens: 128000,
    },
    ModelEntry {
        id: "gpt-5-mini",
        name: "GPT-5 Mini",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 0.25,
        cost_output: 2.0,
        cost_cache_read: 0.025,
        cost_cache_write: 0.0,
        cost_thinking: 2.0,
        context_window: 400000,
        max_tokens: 128000,
    },
    ModelEntry {
        id: "gpt-5-nano",
        name: "GPT-5 Nano",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 0.05,
        cost_output: 0.4,
        cost_cache_read: 0.005,
        cost_cache_write: 0.0,
        cost_thinking: 0.4,
        context_window: 400000,
        max_tokens: 128000,
    },
    ModelEntry {
        id: "gpt-5-pro",
        name: "GPT-5 Pro",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 15.0,
        cost_output: 120.0,
        cost_cache_read: 0.0,
        cost_cache_write: 0.0,
        cost_thinking: 120.0,
        context_window: 400000,
        max_tokens: 272000,
    },
    ModelEntry {
        id: "gpt-5.1",
        name: "GPT-5.1",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 1.25,
        cost_output: 10.0,
        cost_cache_read: 0.13,
        cost_cache_write: 0.0,
        cost_thinking: 10.0,
        context_window: 400000,
        max_tokens: 128000,
    },
    ModelEntry {
        id: "gpt-5.1-chat-latest",
        name: "GPT-5.1 Chat",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 1.25,
        cost_output: 10.0,
        cost_cache_read: 0.125,
        cost_cache_write: 0.0,
        cost_thinking: 10.0,
        context_window: 128000,
        max_tokens: 16384,
    },
    ModelEntry {
        id: "gpt-5.1-codex",
        name: "GPT-5.1 Codex",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 1.25,
        cost_output: 10.0,
        cost_cache_read: 0.125,
        cost_cache_write: 0.0,
        cost_thinking: 10.0,
        context_window: 400000,
        max_tokens: 128000,
    },
    ModelEntry {
        id: "gpt-5.1-codex-max",
        name: "GPT-5.1 Codex Max",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 1.25,
        cost_output: 10.0,
        cost_cache_read: 0.125,
        cost_cache_write: 0.0,
        cost_thinking: 10.0,
        context_window: 400000,
        max_tokens: 128000,
    },
    ModelEntry {
        id: "gpt-5.1-codex-mini",
        name: "GPT-5.1 Codex mini",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 0.25,
        cost_output: 2.0,
        cost_cache_read: 0.025,
        cost_cache_write: 0.0,
        cost_thinking: 2.0,
        context_window: 400000,
        max_tokens: 128000,
    },
    ModelEntry {
        id: "gpt-5.2",
        name: "GPT-5.2",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 1.75,
        cost_output: 14.0,
        cost_cache_read: 0.175,
        cost_cache_write: 0.0,
        cost_thinking: 14.0,
        context_window: 400000,
        max_tokens: 128000,
    },
    ModelEntry {
        id: "gpt-5.2-chat-latest",
        name: "GPT-5.2 Chat",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 1.75,
        cost_output: 14.0,
        cost_cache_read: 0.175,
        cost_cache_write: 0.0,
        cost_thinking: 14.0,
        context_window: 128000,
        max_tokens: 16384,
    },
    ModelEntry {
        id: "gpt-5.2-codex",
        name: "GPT-5.2 Codex",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 1.75,
        cost_output: 14.0,
        cost_cache_read: 0.175,
        cost_cache_write: 0.0,
        cost_thinking: 14.0,
        context_window: 400000,
        max_tokens: 128000,
    },
    ModelEntry {
        id: "gpt-5.2-pro",
        name: "GPT-5.2 Pro",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 21.0,
        cost_output: 168.0,
        cost_cache_read: 0.0,
        cost_cache_write: 0.0,
        cost_thinking: 168.0,
        context_window: 400000,
        max_tokens: 128000,
    },
    ModelEntry {
        id: "gpt-5.3-codex",
        name: "GPT-5.3 Codex",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 1.75,
        cost_output: 14.0,
        cost_cache_read: 0.175,
        cost_cache_write: 0.0,
        cost_thinking: 14.0,
        context_window: 400000,
        max_tokens: 128000,
    },
    ModelEntry {
        id: "gpt-5.3-codex-spark",
        name: "GPT-5.3 Codex Spark",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 1.75,
        cost_output: 14.0,
        cost_cache_read: 0.175,
        cost_cache_write: 0.0,
        cost_thinking: 14.0,
        context_window: 128000,
        max_tokens: 32000,
    },
    ModelEntry {
        id: "o1",
        name: "o1",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 15.0,
        cost_output: 60.0,
        cost_cache_read: 7.5,
        cost_cache_write: 0.0,
        cost_thinking: 60.0,
        context_window: 200000,
        max_tokens: 100000,
    },
    ModelEntry {
        id: "o1-pro",
        name: "o1-pro",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 150.0,
        cost_output: 600.0,
        cost_cache_read: 0.0,
        cost_cache_write: 0.0,
        cost_thinking: 600.0,
        context_window: 200000,
        max_tokens: 100000,
    },
    ModelEntry {
        id: "o3",
        name: "o3",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 2.0,
        cost_output: 8.0,
        cost_cache_read: 0.5,
        cost_cache_write: 0.0,
        cost_thinking: 8.0,
        context_window: 200000,
        max_tokens: 100000,
    },
    ModelEntry {
        id: "o3-deep-research",
        name: "o3-deep-research",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 10.0,
        cost_output: 40.0,
        cost_cache_read: 2.5,
        cost_cache_write: 0.0,
        cost_thinking: 40.0,
        context_window: 200000,
        max_tokens: 100000,
    },
    ModelEntry {
        id: "o3-mini",
        name: "o3-mini",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: false,
        cost_input: 1.1,
        cost_output: 4.4,
        cost_cache_read: 0.55,
        cost_cache_write: 0.0,
        cost_thinking: 4.4,
        context_window: 200000,
        max_tokens: 100000,
    },
    ModelEntry {
        id: "o3-pro",
        name: "o3-pro",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 20.0,
        cost_output: 80.0,
        cost_cache_read: 0.0,
        cost_cache_write: 0.0,
        cost_thinking: 80.0,
        context_window: 200000,
        max_tokens: 100000,
    },
    ModelEntry {
        id: "o4-mini",
        name: "o4-mini",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 1.1,
        cost_output: 4.4,
        cost_cache_read: 0.28,
        cost_cache_write: 0.0,
        cost_thinking: 4.4,
        context_window: 200000,
        max_tokens: 100000,
    },
    ModelEntry {
        id: "o4-mini-deep-research",
        name: "o4-mini-deep-research",
        provider: "OpenAI",
        api: "OpenAIResponses",
        base_url: "https://api.openai.com/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 2.0,
        cost_output: 8.0,
        cost_cache_read: 0.5,
        cost_cache_write: 0.0,
        cost_thinking: 8.0,
        context_window: 200000,
        max_tokens: 100000,
    },
    ModelEntry {
        id: "grok-2",
        name: "Grok 2",
        provider: "xAI",
        api: "OpenAICompletions",
        base_url: "https://api.x.ai/v1",
        reasoning: false,
        input_text: true,
        input_image: false,
        cost_input: 2.0,
        cost_output: 10.0,
        cost_cache_read: 2.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 131072,
        max_tokens: 8192,
    },
    ModelEntry {
        id: "grok-2-1212",
        name: "Grok 2 (1212)",
        provider: "xAI",
        api: "OpenAICompletions",
        base_url: "https://api.x.ai/v1",
        reasoning: false,
        input_text: true,
        input_image: false,
        cost_input: 2.0,
        cost_output: 10.0,
        cost_cache_read: 2.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 131072,
        max_tokens: 8192,
    },
    ModelEntry {
        id: "grok-2-latest",
        name: "Grok 2 Latest",
        provider: "xAI",
        api: "OpenAICompletions",
        base_url: "https://api.x.ai/v1",
        reasoning: false,
        input_text: true,
        input_image: false,
        cost_input: 2.0,
        cost_output: 10.0,
        cost_cache_read: 2.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 131072,
        max_tokens: 8192,
    },
    ModelEntry {
        id: "grok-2-vision",
        name: "Grok 2 Vision",
        provider: "xAI",
        api: "OpenAICompletions",
        base_url: "https://api.x.ai/v1",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 2.0,
        cost_output: 10.0,
        cost_cache_read: 2.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 8192,
        max_tokens: 4096,
    },
    ModelEntry {
        id: "grok-2-vision-1212",
        name: "Grok 2 Vision (1212)",
        provider: "xAI",
        api: "OpenAICompletions",
        base_url: "https://api.x.ai/v1",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 2.0,
        cost_output: 10.0,
        cost_cache_read: 2.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 8192,
        max_tokens: 4096,
    },
    ModelEntry {
        id: "grok-2-vision-latest",
        name: "Grok 2 Vision Latest",
        provider: "xAI",
        api: "OpenAICompletions",
        base_url: "https://api.x.ai/v1",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 2.0,
        cost_output: 10.0,
        cost_cache_read: 2.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 8192,
        max_tokens: 4096,
    },
    ModelEntry {
        id: "grok-3",
        name: "Grok 3",
        provider: "xAI",
        api: "OpenAICompletions",
        base_url: "https://api.x.ai/v1",
        reasoning: false,
        input_text: true,
        input_image: false,
        cost_input: 3.0,
        cost_output: 15.0,
        cost_cache_read: 0.75,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 131072,
        max_tokens: 8192,
    },
    ModelEntry {
        id: "grok-3-fast",
        name: "Grok 3 Fast",
        provider: "xAI",
        api: "OpenAICompletions",
        base_url: "https://api.x.ai/v1",
        reasoning: false,
        input_text: true,
        input_image: false,
        cost_input: 5.0,
        cost_output: 25.0,
        cost_cache_read: 1.25,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 131072,
        max_tokens: 8192,
    },
    ModelEntry {
        id: "grok-3-fast-latest",
        name: "Grok 3 Fast Latest",
        provider: "xAI",
        api: "OpenAICompletions",
        base_url: "https://api.x.ai/v1",
        reasoning: false,
        input_text: true,
        input_image: false,
        cost_input: 5.0,
        cost_output: 25.0,
        cost_cache_read: 1.25,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 131072,
        max_tokens: 8192,
    },
    ModelEntry {
        id: "grok-3-latest",
        name: "Grok 3 Latest",
        provider: "xAI",
        api: "OpenAICompletions",
        base_url: "https://api.x.ai/v1",
        reasoning: false,
        input_text: true,
        input_image: false,
        cost_input: 3.0,
        cost_output: 15.0,
        cost_cache_read: 0.75,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 131072,
        max_tokens: 8192,
    },
    ModelEntry {
        id: "grok-3-mini",
        name: "Grok 3 Mini",
        provider: "xAI",
        api: "OpenAICompletions",
        base_url: "https://api.x.ai/v1",
        reasoning: true,
        input_text: true,
        input_image: false,
        cost_input: 0.3,
        cost_output: 0.5,
        cost_cache_read: 0.075,
        cost_cache_write: 0.0,
        cost_thinking: 0.5,
        context_window: 131072,
        max_tokens: 8192,
    },
    ModelEntry {
        id: "grok-3-mini-fast",
        name: "Grok 3 Mini Fast",
        provider: "xAI",
        api: "OpenAICompletions",
        base_url: "https://api.x.ai/v1",
        reasoning: true,
        input_text: true,
        input_image: false,
        cost_input: 0.6,
        cost_output: 4.0,
        cost_cache_read: 0.15,
        cost_cache_write: 0.0,
        cost_thinking: 4.0,
        context_window: 131072,
        max_tokens: 8192,
    },
    ModelEntry {
        id: "grok-3-mini-fast-latest",
        name: "Grok 3 Mini Fast Latest",
        provider: "xAI",
        api: "OpenAICompletions",
        base_url: "https://api.x.ai/v1",
        reasoning: true,
        input_text: true,
        input_image: false,
        cost_input: 0.6,
        cost_output: 4.0,
        cost_cache_read: 0.15,
        cost_cache_write: 0.0,
        cost_thinking: 4.0,
        context_window: 131072,
        max_tokens: 8192,
    },
    ModelEntry {
        id: "grok-3-mini-latest",
        name: "Grok 3 Mini Latest",
        provider: "xAI",
        api: "OpenAICompletions",
        base_url: "https://api.x.ai/v1",
        reasoning: true,
        input_text: true,
        input_image: false,
        cost_input: 0.3,
        cost_output: 0.5,
        cost_cache_read: 0.075,
        cost_cache_write: 0.0,
        cost_thinking: 0.5,
        context_window: 131072,
        max_tokens: 8192,
    },
    ModelEntry {
        id: "grok-4",
        name: "Grok 4",
        provider: "xAI",
        api: "OpenAICompletions",
        base_url: "https://api.x.ai/v1",
        reasoning: true,
        input_text: true,
        input_image: false,
        cost_input: 3.0,
        cost_output: 15.0,
        cost_cache_read: 0.75,
        cost_cache_write: 0.0,
        cost_thinking: 15.0,
        context_window: 256000,
        max_tokens: 64000,
    },
    ModelEntry {
        id: "grok-4-1-fast",
        name: "Grok 4.1 Fast",
        provider: "xAI",
        api: "OpenAICompletions",
        base_url: "https://api.x.ai/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 0.2,
        cost_output: 0.5,
        cost_cache_read: 0.05,
        cost_cache_write: 0.0,
        cost_thinking: 0.5,
        context_window: 2000000,
        max_tokens: 30000,
    },
    ModelEntry {
        id: "grok-4-1-fast-non-reasoning",
        name: "Grok 4.1 Fast (Non-Reasoning)",
        provider: "xAI",
        api: "OpenAICompletions",
        base_url: "https://api.x.ai/v1",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 0.2,
        cost_output: 0.5,
        cost_cache_read: 0.05,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 2000000,
        max_tokens: 30000,
    },
    ModelEntry {
        id: "grok-4-fast",
        name: "Grok 4 Fast",
        provider: "xAI",
        api: "OpenAICompletions",
        base_url: "https://api.x.ai/v1",
        reasoning: true,
        input_text: true,
        input_image: true,
        cost_input: 0.2,
        cost_output: 0.5,
        cost_cache_read: 0.05,
        cost_cache_write: 0.0,
        cost_thinking: 0.5,
        context_window: 2000000,
        max_tokens: 30000,
    },
    ModelEntry {
        id: "grok-4-fast-non-reasoning",
        name: "Grok 4 Fast (Non-Reasoning)",
        provider: "xAI",
        api: "OpenAICompletions",
        base_url: "https://api.x.ai/v1",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 0.2,
        cost_output: 0.5,
        cost_cache_read: 0.05,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 2000000,
        max_tokens: 30000,
    },
    ModelEntry {
        id: "grok-beta",
        name: "Grok Beta",
        provider: "xAI",
        api: "OpenAICompletions",
        base_url: "https://api.x.ai/v1",
        reasoning: false,
        input_text: true,
        input_image: false,
        cost_input: 5.0,
        cost_output: 15.0,
        cost_cache_read: 5.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 131072,
        max_tokens: 4096,
    },
    ModelEntry {
        id: "grok-code-fast-1",
        name: "Grok Code Fast 1",
        provider: "xAI",
        api: "OpenAICompletions",
        base_url: "https://api.x.ai/v1",
        reasoning: true,
        input_text: true,
        input_image: false,
        cost_input: 0.2,
        cost_output: 1.5,
        cost_cache_read: 0.02,
        cost_cache_write: 0.0,
        cost_thinking: 1.5,
        context_window: 256000,
        max_tokens: 10000,
    },
    ModelEntry {
        id: "grok-vision-beta",
        name: "Grok Vision Beta",
        provider: "xAI",
        api: "OpenAICompletions",
        base_url: "https://api.x.ai/v1",
        reasoning: false,
        input_text: true,
        input_image: true,
        cost_input: 5.0,
        cost_output: 15.0,
        cost_cache_read: 5.0,
        cost_cache_write: 0.0,
        cost_thinking: 0.0,
        context_window: 8192,
        max_tokens: 4096,
    },
];
